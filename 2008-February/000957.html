<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Opensim-dev] Concerning recent grid instability and	inconsistency
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/opensim-dev/2008-February/index.html" >
   <LINK REL="made" HREF="mailto:opensim-dev%40lists.berlios.de?Subject=Re%3A%20%5BOpensim-dev%5D%20Concerning%20recent%20grid%20instability%20and%0A%09inconsistency&In-Reply-To=%3C970c50810802281627g64bc71ebt5c197e9ca7294a57%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000940.html">
   <LINK REL="Next"  HREF="000961.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Opensim-dev] Concerning recent grid instability and	inconsistency</H1>
    <B>Dalien Talbot</B> 
    <A HREF="mailto:opensim-dev%40lists.berlios.de?Subject=Re%3A%20%5BOpensim-dev%5D%20Concerning%20recent%20grid%20instability%20and%0A%09inconsistency&In-Reply-To=%3C970c50810802281627g64bc71ebt5c197e9ca7294a57%40mail.gmail.com%3E"
       TITLE="[Opensim-dev] Concerning recent grid instability and	inconsistency">dalienta at gmail.com
       </A><BR>
    <I>Fri Feb 29 01:27:31 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="000940.html">[Opensim-dev] Concerning recent grid instability and inconsistency
</A></li>
        <LI>Next message: <A HREF="000961.html">[Opensim-dev] Concerning recent grid instability	and	inconsistency
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#957">[ date ]</a>
              <a href="thread.html#957">[ thread ]</a>
              <a href="subject.html#957">[ subject ]</a>
              <a href="author.html#957">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hiro,

excellent post.
comments inline.

On Wed, Feb 27, 2008 at 6:59 PM, James Stallings II &lt;
<A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">james.stallings at gmail.com</A>&gt; wrote:

&gt;<i>
</I>&gt;<i> Early this morning there was (yet another) instance where certain regions
</I>&gt;<i> could be readily accessed by some and could not be accessed at all by
</I>&gt;<i> others.
</I>&gt;<i>
</I>&gt;<i> This led to an insightfull discussion on IRC this morning, which I will
</I>&gt;<i> attach for your convenience.
</I>&gt;<i>
</I>&gt;<i> Here are some high points:
</I>&gt;<i>
</I>&gt;<i> [image: :arrow:] Various users were able to access WP reliably last night
</I>&gt;<i> while others were completely unable to do so. The consistent relevant factor
</I>&gt;<i> was a high ping time from the affected clients to the region server in
</I>&gt;<i> question. A properly executed traceroute revealed that the network fault lay
</I>&gt;<i> with level3 networks, between the affected clients and the region server in
</I>&gt;<i> question.
</I>&gt;<i>
</I>&gt;<i> [image: :arrow:] recently I was graced with the company of many new
</I>&gt;<i> neighbors on the grid. With the new neighbors came complete instability with
</I>&gt;<i> respect to my region server. Some of the instabilities were my own doing.
</I>&gt;<i> Fixing them did not completely address the problem. A subsequent relocation
</I>&gt;<i> to a neighbor-free location on the grid did.
</I>&gt;<i>
</I>
I wonder if this is inter-region comms, or region-grid comms, or
region-client comms that were the issue - do we know by chance what of them
were the culprits ? Or the sequence of events that would help to pinpoint
this ?


&gt;<i>
</I>&gt;<i> [image: :arrow:] one of our newer contributors has audited much of the
</I>&gt;<i> low-level packet handling code and found it to be in want of some
</I>&gt;<i> rearchitecting in the interest of efficiency. This is a salient point; if
</I>&gt;<i> the communications code upon which the grid relies for region&lt;&gt;region and
</I>&gt;<i> client&lt;&gt;region communications is not optimum, we cannot count on operations
</I>&gt;<i> to be optimum. This also has profound implications for troubleshooting, as
</I>&gt;<i> all diagnostic data arrives via the conduits implemented by this low-level
</I>&gt;<i> comms code.
</I>&gt;<i>
</I>

I thought region&lt;-&gt;region was not working by means of packet handling, and
it was primarily for region&lt;-&gt;client comms - do we have any more specifics ?


&gt;<i>
</I>&gt;<i> [image: :arrow:] adjacent misconfigured regions have been demonstrated to
</I>&gt;<i> have a significant impact on a given region's stability. Something needs to
</I>&gt;<i> be done to address this.
</I>&gt;<i>
</I>
again, first thing to do imho is to find out what is the trigger.

(I will save my usual rant that the &quot;centralized&quot; model is not scalable in a
&quot;large&quot; (as in &quot;millions of regions&quot; deployment model - we did have some
discussion with Ahzz on this but did not have the time yet to make the
sifnificant progress... The only thing I did is for now importing a
bsd-licensed DNS resolver code - we were agreeing that (ab)using the TXT
records in DNS is certainly a good way to go towards a more scalable system.


&gt;<i> I will present some talking points in terms of these roles and their
</I>&gt;<i> goals.
</I>&gt;<i>
</I>&gt;<i> The set of roles and goals of the OSGrid may be summarized as a brief mission
</I>&gt;<i> statement which I characterise as follows:
</I>&gt;<i>
</I>&gt;<i> OSGrid exists as a multirole support operation supporting and conducting
</I>&gt;<i> testing pursuant to the development of OpenSim virtual reality/telepresence
</I>&gt;<i> software. Further, it exists to provide a free parking service for the
</I>&gt;<i> development and testing community, both for pure testing and content
</I>&gt;<i> hosting. Finally, OSGrid exists to develop and drive development of
</I>&gt;<i> grid-related tools and/or code, whether as freestanding utilities or source
</I>&gt;<i> for contribution to the codebase of OpenSim.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Pursuant to fulfillment of these roles, a course of action needs be
</I>&gt;<i> devised which facilitates all of these objectives simultaneously. Here is a
</I>&gt;<i> plan which seeks to accomplish this. Note that some key points are short
</I>&gt;<i> term; others, less so:
</I>&gt;<i>
</I>&gt;<i> [image: :idea:] Packet handling technology critique. Involve directly
</I>&gt;<i> those who have worked on this code in the past with those who are interested
</I>&gt;<i> in carrying the work forward. Get either a commitment from it's original
</I>&gt;<i> authors to return to active development, or alternatively an informal
</I>&gt;<i> hand-off of the work to this group. Then perform a systematic audit on this
</I>&gt;<i> code, as a group. Document it as we go. Explaining how code works to a piece
</I>&gt;<i> of paper can show up just as many flaws as a trial run. There's the side
</I>&gt;<i> benefit of generating thorough documentation.
</I>&gt;<i>
</I>

again - packet handling, afaik, pertains largely to client&lt;-&gt;region
communications - please correct me if I am wrong. Indeed this should become
the area of focus if we determine it is the botteneck, but I would think the
troubles like in the region&lt;-&gt;region, and region&lt;-&gt;grid server comms, which
are done by other means.

&gt;<i>
</I>&gt;<i> One sequence of events currently in progress with respect to this, is that
</I>&gt;<i> several of our commercial contributors are about to introduce a major set of
</I>&gt;<i> stability and load balancing patches. This set of patches might well replace
</I>&gt;<i> or repair the affected code, so this may in fact become a non-issue.
</I>&gt;<i>
</I>&gt;<i> This does not mean we can afford to sit and wait for them to make the
</I>&gt;<i> drop. What we can take immediate action on, is to prepare to profile the
</I>&gt;<i> performance impact in quantitative ways once this code has been dropped. In
</I>&gt;<i> this interest, ChrisD will be placing some regions alongside mine out in the
</I>&gt;<i> open; our intention is to maintain a seperate 'island', where we can
</I>&gt;<i> excercise fine-grained control over who our neighbors are (and more
</I>&gt;<i> importantly, fine-grained control of the neighbor configuration) for testing
</I>&gt;<i> purposes.
</I>&gt;<i>
</I>
yes - so pertaining to my comments above - narrowing down what exactly is
the trigger for the slowness is the key.


&gt;<i>
</I>&gt;<i> We also hope to be able to prove our theory about brokenly configured
</I>&gt;<i> adjacent regions. If you bring up a region adjacent to us, we will likely
</I>&gt;<i> ask you to move it or remove it ourselves if we are unable to reach you.
</I>&gt;<i>
</I>&gt;<i> [image: :idea:] Set up an automated vetting process for incoming regions
</I>&gt;<i> on the grid. Say, submit region xml files via HTTP/POST, and have them
</I>&gt;<i> programatically checked for syntactical correctness, geographical
</I>&gt;<i> collisions, network reachability, port configuration consistency,
</I>&gt;<i> completness of information, etc. before allowing a final connection with
</I>&gt;<i> grid services.
</I>&gt;<i>
</I>
+1. Once we understand what kind of misconfigurations are causing the issues
- maybe we should go even further and address the root causes of them,
rather than checking the configuration.


&gt;<i>
</I>&gt;<i> This also introduces a logical point for a payment collection/verification
</I>&gt;<i> process for that day when we have a salable service, for those who are
</I>&gt;<i> interested in providing for-pay grid services at that time.
</I>&gt;<i>
</I>
This would provide a roadblock. The payment should still be a hook outside
of the &quot;automated&quot; process. (like, providing a crypto token of sorts, which
would be checked at the time of the region coming up)


&gt;<i>
</I>&gt;<i> [image: :idea:] Establish an effective heartbeat mechanism between region
</I>&gt;<i> servers and grid server. If the heartbeat goes away, the region table entry
</I>&gt;<i> is appropriately updated to reflect the region state, and except for
</I>&gt;<i> geographic purposes and region heartbeat response, the region would be
</I>&gt;<i> ignored by grid services (as if it were not there). If/when the region
</I>&gt;<i> produces new signs of life, it would then be returned to active
</I>&gt;<i> participation with grid services. This could be taken a step further with
</I>&gt;<i> longterm monitoring of the region heartbeat.
</I>&gt;<i>
</I>
I think Ahzz had some patch in mantis and his git repo on this. Since I am
not much into centralized grid comms, I did not commit it - I think it was
introducing some changes to the SQL tables...


&gt;<i>
</I>&gt;<i> Logic is implied that after some configurable long period without a
</I>&gt;<i> heartbeat the region could be made available for purging from the tables
</I>&gt;<i> completely, either automatically or with operator intervention. The benefits
</I>&gt;<i> in bandwidth and cycles recovered from retry requests and threads locked
</I>&gt;<i> while waiting on unresponsive regions would far exceed the relatively minor
</I>&gt;<i> hit taken in producing and servicing a heartbeat.
</I>

I did start early experiments with using the DHT as a &quot;grid service&quot; - I've
installed a couple of bamboo DHT instances. Although obviously this drags a
few other issues (like the questions of &quot;trust&quot; between the operators of
instances of DHT, etc. Maybe having the DNS records that are periodically
updated, could be a better solution. We were discussing that kind of stuff
with Ahzz.. Again, the time issue :(

My personal opinion is that having a &quot;pay-to-join-the-grid&quot; is the wrong
business model as it forces the competition between the grid operators. It
should be &quot;pay-to-store-your-identity&quot; or
&quot;pay-to-store-your-assets-and-other-junk&quot; or &quot;pay-to-store-your-sim&quot; - and
the architecture should be driven around that, rather than the central
control point (aka single point of failure:) that the grid services really
are.

But all of this is a more long-term view, for the short term the most
important thing is to try to figure out what exactly is the reason for the
issues - and try to address it.

/d
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="https://lists.berlios.de/pipermail/opensim-dev/attachments/20080229/409c07c7/attachment.html">https://lists.berlios.de/pipermail/opensim-dev/attachments/20080229/409c07c7/attachment.html</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000940.html">[Opensim-dev] Concerning recent grid instability and inconsistency
</A></li>
	<LI>Next message: <A HREF="000961.html">[Opensim-dev] Concerning recent grid instability	and	inconsistency
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#957">[ date ]</a>
              <a href="thread.html#957">[ thread ]</a>
              <a href="subject.html#957">[ subject ]</a>
              <a href="author.html#957">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/opensim-dev">More information about the Opensim-dev
mailing list</a><br>
</body></html>
