<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Opensim-dev] networking issues
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/opensim-dev/2011-March/index.html" >
   <LINK REL="made" HREF="mailto:opensim-dev%40lists.berlios.de?Subject=Re%3A%20%5BOpensim-dev%5D%20networking%20issues&In-Reply-To=%3CBANLkTi%3DV5ZTmaSZi%2ByZ_myU9UTL6W-Czkw%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="010069.html">
   <LINK REL="Next"  HREF="010072.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Opensim-dev] networking issues</H1>
    <B>Dahlia Trimble</B> 
    <A HREF="mailto:opensim-dev%40lists.berlios.de?Subject=Re%3A%20%5BOpensim-dev%5D%20networking%20issues&In-Reply-To=%3CBANLkTi%3DV5ZTmaSZi%2ByZ_myU9UTL6W-Czkw%40mail.gmail.com%3E"
       TITLE="[Opensim-dev] networking issues">dahliatrimble at gmail.com
       </A><BR>
    <I>Mon Mar 28 20:57:51 CEST 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="010069.html">[Opensim-dev] networking issues
</A></li>
        <LI>Next message: <A HREF="010072.html">[Opensim-dev] networking issues
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10071">[ date ]</a>
              <a href="thread.html#10071">[ thread ]</a>
              <a href="subject.html#10071">[ subject ]</a>
              <a href="author.html#10071">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>the viewer discards small changes anyway if avatar imposters are enabled

On Mon, Mar 28, 2011 at 11:54 AM, Melanie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">melanie at t-data.com</A>&gt; wrote:

&gt;<i> No, we can't discard small changes. As the avatar comes closer, they
</I>&gt;<i> would be seen out of place, e.g. someone building in the distance
</I>&gt;<i> would move prims and then you come closer to look and all prims
</I>&gt;<i> would be out of place.
</I>&gt;<i>
</I>&gt;<i> Melanie
</I>&gt;<i>
</I>&gt;<i> Dahlia Trimble wrote:
</I>&gt;<i> &gt; a couple thoughts..
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Perhaps resend timeout period could be a function of throttle setting
</I>&gt;<i> and/or
</I>&gt;<i> &gt; measured packet acknowledgement time per-client? (provided we measure
</I>&gt;<i> it).
</I>&gt;<i> &gt; That may prevent excessive resend processing that may not be necessary.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; On the distance prioritization, could small changed in object
</I>&gt;<i> translations
</I>&gt;<i> &gt; be discarded from the prioritization queues/resend buffers for distant
</I>&gt;<i> &gt; objects when new updates occur for those objects? Small changes may not
</I>&gt;<i> be
</I>&gt;<i> &gt; noticeable from the viewer perspective anyway.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; On Mon, Mar 28, 2011 at 10:48 AM, Teravus Ovares &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">teravus at gmail.com</A>&gt;
</I>&gt;<i> wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; Here are a few facts that I've personally discovered while working
</I>&gt;<i> &gt;&gt; with LLClientView.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 1. It has been noted that people with poor connections to the
</I>&gt;<i> &gt;&gt; simulator do consume more bandwidth, cpu, and have a generally worse
</I>&gt;<i> &gt;&gt; experience.   This has been tested and profiled extensively.    This
</I>&gt;<i> &gt;&gt; may seem like a small issue because what it's doing is so basic...
</I>&gt;<i> &gt;&gt; however the frequency in which this occurs is a real cause of
</I>&gt;<i> &gt;&gt; performance issues.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 2. It's also noted that the CPU used in these cases reduces the CPU
</I>&gt;<i> &gt;&gt; available to the rest of the simulator resulting in a lower quality of
</I>&gt;<i> &gt;&gt; service for the rest of the people on the simulator.
</I>&gt;<i> &gt;&gt; This has been seen in the profiling and has been qualitatively
</I>&gt;<i> &gt;&gt; observed by a large number of users connected and everything is OK and
</I>&gt;<i> &gt;&gt; then a 'problem connection' user connecting causing a wide range of
</I>&gt;<i> &gt;&gt; issues.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 3. It's also noted that lowering the outgoing UDP packet throttles
</I>&gt;<i> &gt;&gt; beyond a certain point results in perpetual queuing and resends.
</I>&gt;<i> &gt;&gt; This was tested by using a throttle multiplier last year that was
</I>&gt;<i> &gt;&gt; implemented by justincc.  I'm not sure if the multiplier is still
</I>&gt;<i> &gt;&gt; there.   It's most easily seen with image packets.   Again, I note
</I>&gt;<i> &gt;&gt; that the packets are not rebuilt going from the regular outbound queue
</I>&gt;<i> &gt;&gt; to the resend queue.    The resend queue is /supposed/ to be used to
</I>&gt;<i> &gt;&gt; quickly get data that is essential to the client after attempting to
</I>&gt;<i> &gt;&gt; send once already.   The UDP spec declares the maximum resend to be 2
</I>&gt;<i> &gt;&gt; times, however there has been some considerable debate on whether or
</I>&gt;<i> &gt;&gt; not OpenSimulator should follow that specific specification item
</I>&gt;<i> &gt;&gt; leading to a configuration option to enable perpetual resends
</I>&gt;<i> &gt;&gt; (Implemented by Melanie).  The configuration item was named similar
</I>&gt;<i> &gt;&gt; to, 'reliable is important' or something like that.   I'm not sure if
</I>&gt;<i> &gt;&gt; the configuration item survived the many revisions however I suspect
</I>&gt;<i> &gt;&gt; that it did.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 4. It's also noted that raising the packet throttles beyond what the
</I>&gt;<i> &gt;&gt; connection can support results in resending almost every packet the
</I>&gt;<i> &gt;&gt; maximum amount of times before the limit is reached.
</I>&gt;<i> &gt;&gt; This is easily reproducible by setting the connection (in the client)
</I>&gt;<i> &gt;&gt; to the maximum and connecting to a region that you've never been to
</I>&gt;<i> &gt;&gt; before on a sub par connection.   Before the client adjusts and
</I>&gt;<i> &gt;&gt; requests a lower throttle setting there's massive data loss and
</I>&gt;<i> &gt;&gt; massive re-queuing.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 5. The client tries to adjust the throttle settings based on network
</I>&gt;<i> &gt;&gt; conditions.   This can be observed by monitoring the packet that sets
</I>&gt;<i> &gt;&gt; the throttles and dragging the bar to maximum.   After a certain
</I>&gt;<i> &gt;&gt; amount of resends, the client will call the set throttle packet with
</I>&gt;<i> &gt;&gt; reduced settings (some argue that it doesn't do that fast enough).
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; 6. A user who has connected previously to the simulator will use less
</I>&gt;<i> &gt;&gt; resources then a user who has never connected to the simulator.  (this
</I>&gt;<i> &gt;&gt; is mostly because of the image cache on the client).    Any client
</I>&gt;<i> &gt;&gt; that uses CAPS images will use less resources then one that uses
</I>&gt;<i> &gt;&gt; LLUDP.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; When working with the packet queues, it's essential to understand
</I>&gt;<i> &gt;&gt; those 6 observations.   Even though, the place where you tend to see
</I>&gt;<i> &gt;&gt; the issues with queuing is the image queue over LLUDP, the principles
</I>&gt;<i> &gt;&gt; apply to all of the udp queues.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; Regards
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; Teravus
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; On Mon, Mar 28, 2011 at 1:00 PM, Mic Bowman &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">cmickeyb at gmail.com</A>&gt; wrote:
</I>&gt;<i> &gt;&gt; &gt; Over the last several weeks, Dan Lake &amp; I have been looking some of
</I>&gt;<i> the
</I>&gt;<i> &gt;&gt; &gt; networking performance issues in opensim. As always, our concerns are
</I>&gt;<i> &gt;&gt; with
</I>&gt;<i> &gt;&gt; &gt; the problems caused by very complex scenes with very large numbers of
</I>&gt;<i> &gt;&gt; &gt; avatars. However, I think some of the issues we have found will
</I>&gt;<i> generally
</I>&gt;<i> &gt;&gt; &gt; improve networking with OpenSim. Since the behavior represents a
</I>&gt;<i> fairly
</I>&gt;<i> &gt;&gt; &gt; significant change in behavior (though the number of lines of code is
</I>&gt;<i> not
</I>&gt;<i> &gt;&gt; &gt; great), I'm going to put this into a separate branch for testing
</I>&gt;<i> (called
</I>&gt;<i> &gt;&gt; &gt; queuetest) in the opensim git repository.
</I>&gt;<i> &gt;&gt; &gt; We've found several problems with the current
</I>&gt;<i> &gt;&gt; &gt; networking/prioritization code.
</I>&gt;<i> &gt;&gt; &gt; * Reprioritization is completely broken for SceneObjectParts. On
</I>&gt;<i> &gt;&gt; &gt; reprioritization, the current code uses the localid stored in the
</I>&gt;<i> scene
</I>&gt;<i> &gt;&gt; &gt; Entities list but since the scene does not store the localid for SOPs,
</I>&gt;<i> &gt;&gt; that
</I>&gt;<i> &gt;&gt; &gt; attempt always fails. So the original priority of the SOP continues to
</I>&gt;<i> be
</I>&gt;<i> &gt;&gt; &gt; used. This could be the cause of some problems since the initial
</I>&gt;<i> &gt;&gt; &gt; prioritization assumes position 128,128. I don't understand all the
</I>&gt;<i> &gt;&gt; possible
</I>&gt;<i> &gt;&gt; &gt; ramifications, but suffice it to say, using the localid is causing
</I>&gt;<i> &gt;&gt; &gt; problems.
</I>&gt;<i> &gt;&gt; &gt; Fix: The sceneentity is already stored in the update, just use that
</I>&gt;<i> &gt;&gt; instead
</I>&gt;<i> &gt;&gt; &gt; of the localid.
</I>&gt;<i> &gt;&gt; &gt; * We currently pull (by default) 100 entity updates from the
</I>&gt;<i> entityupdate
</I>&gt;<i> &gt;&gt; &gt; queue and convert them into packets. Once converted into packets, they
</I>&gt;<i> &gt;&gt; are
</I>&gt;<i> &gt;&gt; &gt; then queued again for transmissions. This is a bad thing. Under any
</I>&gt;<i> kind
</I>&gt;<i> &gt;&gt; of
</I>&gt;<i> &gt;&gt; &gt; load, we've measured the time in the packet queue to be up to many
</I>&gt;<i> &gt;&gt; &gt; hundreds/thousands of milliseconds (and to be highly variable). When
</I>&gt;<i> an
</I>&gt;<i> &gt;&gt; &gt; object changes one property and then doesn't change it again, the time
</I>&gt;<i> in
</I>&gt;<i> &gt;&gt; &gt; the packet queue is largely irrelevant. However, if the object is
</I>&gt;<i> &gt;&gt; &gt; continuously changing (an avatar changing position, a physical object
</I>&gt;<i> &gt;&gt; &gt; moving, etc) then the conversion from a entity update to a packet
</I>&gt;<i> &gt;&gt; &quot;freezes&quot;
</I>&gt;<i> &gt;&gt; &gt; the properties to be sent. If the object is continuously changing,
</I>&gt;<i> then
</I>&gt;<i> &gt;&gt; with
</I>&gt;<i> &gt;&gt; &gt; fairly high probability, the packet contains old data (the properties
</I>&gt;<i> of
</I>&gt;<i> &gt;&gt; the
</I>&gt;<i> &gt;&gt; &gt; entity from the point at which it was converted into a packet).
</I>&gt;<i> &gt;&gt; &gt; The real problem is that, in theory, to improve the efficiency of the
</I>&gt;<i> &gt;&gt; &gt; packets (fill up each message) we are grabbing big chunks of updates.
</I>&gt;<i> &gt;&gt; Under
</I>&gt;<i> &gt;&gt; &gt; load, that causes queuing at the packet layer which makes updates
</I>&gt;<i> stale.
</I>&gt;<i> &gt;&gt; &gt; That is... queuing at the packet layer is BAD.
</I>&gt;<i> &gt;&gt; &gt; Fix: We implemented an adaptive algorithm for the number of updates to
</I>&gt;<i> &gt;&gt; grab
</I>&gt;<i> &gt;&gt; &gt; with each pass. We set a target time of 200ms for each iteration. That
</I>&gt;<i> &gt;&gt; &gt; means, we are trying to bound the maximum age of any update in the
</I>&gt;<i> packet
</I>&gt;<i> &gt;&gt; &gt; queue to 200ms. The adaptive algorithm looks a lot like a TCP slow
</I>&gt;<i> start:
</I>&gt;<i> &gt;&gt; &gt; every time we complete an iteration (flush the packet queue) in less
</I>&gt;<i> than
</I>&gt;<i> &gt;&gt; &gt; 200ms we increase linearly the number of updates we take in the next
</I>&gt;<i> &gt;&gt; &gt; iteration (add 5 to the count) and when we don't make it back in
</I>&gt;<i> 200ms,
</I>&gt;<i> &gt;&gt; we
</I>&gt;<i> &gt;&gt; &gt; drop the number we take quadratically (cut the number in half). In our
</I>&gt;<i> &gt;&gt; &gt; experiments with large numbers of moving avatars, this algorithm works
</I>&gt;<i> &gt;&gt; &gt; *very* well. The number of updates taken per iteration stabilizes very
</I>&gt;<i> &gt;&gt; &gt; quickly and the response time is dramatically improved (no &quot;snap back&quot;
</I>&gt;<i> on
</I>&gt;<i> &gt;&gt; &gt; avatars, for example). One difference from the traditional slow
</I>&gt;<i> start...
</I>&gt;<i> &gt;&gt; &gt; since the number of &quot;static&quot; items in the queue is very high when a
</I>&gt;<i> &gt;&gt; client
</I>&gt;<i> &gt;&gt; &gt; first enters a region, we start with the number of updates taken at
</I>&gt;<i> 500.
</I>&gt;<i> &gt;&gt; &gt; that gets the static items out of the queue quickly (and delay doesn't
</I>&gt;<i> &gt;&gt; &gt; matter as much) and the number taken is generally stable before the
</I>&gt;<i> &gt;&gt; &gt; login/teleport screen even goes away.
</I>&gt;<i> &gt;&gt; &gt; * The current prioritization queue can lead to update starvation. The
</I>&gt;<i> &gt;&gt; &gt; prioritization algorithm dumps all entity updates into a single
</I>&gt;<i> ordered
</I>&gt;<i> &gt;&gt; &gt; queue. Lets say you have several hundred avatars moving around in a
</I>&gt;<i> &gt;&gt; scene.
</I>&gt;<i> &gt;&gt; &gt; Since we take a limited number of updates from the queue in each
</I>&gt;<i> &gt;&gt; iteration,
</I>&gt;<i> &gt;&gt; &gt; we will take only the updates for the &quot;closest&quot; (highest priority)
</I>&gt;<i> &gt;&gt; avatars.
</I>&gt;<i> &gt;&gt; &gt; However, since those avatars continue to move, they are re-inserted
</I>&gt;<i> into
</I>&gt;<i> &gt;&gt; the
</I>&gt;<i> &gt;&gt; &gt; priority queue *ahead* of the updates that were already there. So...
</I>&gt;<i> &gt;&gt; unless
</I>&gt;<i> &gt;&gt; &gt; the queue can be completely emptied each iteration or the priority of
</I>&gt;<i> the
</I>&gt;<i> &gt;&gt; &gt; &quot;distant&quot; (low priority) avatars changes, those avatars will never be
</I>&gt;<i> &gt;&gt; &gt; updated.
</I>&gt;<i> &gt;&gt; &gt; Fix: We converted the single priority queue into multiple priority
</I>&gt;<i> queues
</I>&gt;<i> &gt;&gt; &gt; and use fair queuing to retrieve updates from each. Here's how it
</I>&gt;<i> works
</I>&gt;<i> &gt;&gt; &gt; (more or less)... the current metrics (all of the current
</I>&gt;<i> prioritization
</I>&gt;<i> &gt;&gt; &gt; algorithms use distance at some point for prioritization) compute a
</I>&gt;<i> &gt;&gt; distance
</I>&gt;<i> &gt;&gt; &gt; from the avatar/camera to an object. We take the log of that distance
</I>&gt;<i> and
</I>&gt;<i> &gt;&gt; &gt; use that as the index for the queue where we place the update. So
</I>&gt;<i> close
</I>&gt;<i> &gt;&gt; &gt; things go into the highest priority queue and distant things go into
</I>&gt;<i> the
</I>&gt;<i> &gt;&gt; &gt; lowest priority queue. Since the area covered by a priority queue
</I>&gt;<i> grows
</I>&gt;<i> &gt;&gt; as
</I>&gt;<i> &gt;&gt; &gt; the square of the radius, the distant (lowest priority queues) will
</I>&gt;<i> have
</I>&gt;<i> &gt;&gt; the
</I>&gt;<i> &gt;&gt; &gt; most objects while the highest priority queues will have a small
</I>&gt;<i> number
</I>&gt;<i> &gt;&gt; of
</I>&gt;<i> &gt;&gt; &gt; objects. Inside each priority queue, we order the updates by the time
</I>&gt;<i> in
</I>&gt;<i> &gt;&gt; &gt; which they entered the queue. Then we pull a fixed number of updates
</I>&gt;<i> from
</I>&gt;<i> &gt;&gt; &gt; each priority queue each iteration. The result is that local updates
</I>&gt;<i> get
</I>&gt;<i> &gt;&gt; a
</I>&gt;<i> &gt;&gt; &gt; high fraction of the outgoing bandwidth but distant updates are
</I>&gt;<i> &gt;&gt; guaranteed
</I>&gt;<i> &gt;&gt; &gt; to get at least &quot;some&quot; of the bandwidth. No starvation. The current
</I>&gt;<i> &gt;&gt; &gt; prioritization algorithm we implemented is a modification of the &quot;best
</I>&gt;<i> &gt;&gt; &gt; avatar responsiveness&quot; and &quot;front back&quot; in that we use root prim
</I>&gt;<i> location
</I>&gt;<i> &gt;&gt; &gt; for child prims and the priority of updates &quot;in back&quot; of the avatar is
</I>&gt;<i> &gt;&gt; lower
</I>&gt;<i> &gt;&gt; &gt; than updates &quot;in front&quot;. Our experiments show that the fair queuing
</I>&gt;<i> does
</I>&gt;<i> &gt;&gt; &gt; drain the update queue AND continues to provide a disproportionately
</I>&gt;<i> high
</I>&gt;<i> &gt;&gt; &gt; percentage of the bw to &quot;close&quot; updates.
</I>&gt;<i> &gt;&gt; &gt; One other note on this... we should be able to improve the performance
</I>&gt;<i> of
</I>&gt;<i> &gt;&gt; &gt; reprioritization with this approach. If we know the distance an avatar
</I>&gt;<i> &gt;&gt; has
</I>&gt;<i> &gt;&gt; &gt; moved, we only have to reprioritize objects that might have changed
</I>&gt;<i> &gt;&gt; priority
</I>&gt;<i> &gt;&gt; &gt; queues. Haven't implemented this yet but have some ideas for how to do
</I>&gt;<i> &gt;&gt; it.
</I>&gt;<i> &gt;&gt; &gt; * The resend queue is evil. When an update packet is sent (they are
</I>&gt;<i> &gt;&gt; marked
</I>&gt;<i> &gt;&gt; &gt; reliable) it is moved to a queue to await acknowledgement. If no
</I>&gt;<i> &gt;&gt; &gt; acknowledgement is received (in time), the packet is retransmitted and
</I>&gt;<i> &gt;&gt; the
</I>&gt;<i> &gt;&gt; &gt; wait time is doubled and so on... What that means is that a resend
</I>&gt;<i> &gt;&gt; packets
</I>&gt;<i> &gt;&gt; &gt; in a scene that is rapidly changing will often contain updates that
</I>&gt;<i> are
</I>&gt;<i> &gt;&gt; &gt; outdated. That is, when we resend the packet, we are just resending
</I>&gt;<i> old
</I>&gt;<i> &gt;&gt; data
</I>&gt;<i> &gt;&gt; &gt; (and if you're having a lot of resends that means you already have a
</I>&gt;<i> bad
</I>&gt;<i> &gt;&gt; &gt; connection &amp; now you're filling it up with useless data).
</I>&gt;<i> &gt;&gt; &gt; Fix: this isn't implemented yet (help would be appreciated)... we
</I>&gt;<i> think
</I>&gt;<i> &gt;&gt; that
</I>&gt;<i> &gt;&gt; &gt; instead of saving packets for resend... a better solution would be to
</I>&gt;<i> &gt;&gt; keep
</I>&gt;<i> &gt;&gt; &gt; the entity updates that went into the packet. if we don't receive an
</I>&gt;<i> ack
</I>&gt;<i> &gt;&gt; in
</I>&gt;<i> &gt;&gt; &gt; time, then put the entity updates back into the entity update queue
</I>&gt;<i> (with
</I>&gt;<i> &gt;&gt; &gt; entry time from their original enqueuing). That would ensure that we
</I>&gt;<i> send
</I>&gt;<i> &gt;&gt; an
</I>&gt;<i> &gt;&gt; &gt; update for the object &amp; that the data sent is the most recent.
</I>&gt;<i> &gt;&gt; &gt; * One final note... per client bandwidth throttles seem to work very
</I>&gt;<i> &gt;&gt; well.
</I>&gt;<i> &gt;&gt; &gt; however, our experiments with per-simulator throttles was not
</I>&gt;<i> positive.
</I>&gt;<i> &gt;&gt; it
</I>&gt;<i> &gt;&gt; &gt; appeared that a small number of clients was consuming all of the bw
</I>&gt;<i> &gt;&gt; &gt; available to the simulator and the rest were starved. Haven't looked
</I>&gt;<i> into
</I>&gt;<i> &gt;&gt; &gt; this any more.
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt; So...
</I>&gt;<i> &gt;&gt; &gt; Feedback appreciated... there is some logging code (disabled) in the
</I>&gt;<i> &gt;&gt; branch;
</I>&gt;<i> &gt;&gt; &gt; real data would be great. And help testing. there are a number of
</I>&gt;<i> &gt;&gt; &gt; attachment, deletes and so on that i'm not sure work correctly.
</I>&gt;<i> &gt;&gt; &gt; --mic
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt; _______________________________________________
</I>&gt;<i> &gt;&gt; &gt; Opensim-dev mailing list
</I>&gt;<i> &gt;&gt; &gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">Opensim-dev at lists.berlios.de</A>
</I>&gt;<i> &gt;&gt; &gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">https://lists.berlios.de/mailman/listinfo/opensim-dev</A>
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; &gt;
</I>&gt;<i> &gt;&gt; _______________________________________________
</I>&gt;<i> &gt;&gt; Opensim-dev mailing list
</I>&gt;<i> &gt;&gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">Opensim-dev at lists.berlios.de</A>
</I>&gt;<i> &gt;&gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">https://lists.berlios.de/mailman/listinfo/opensim-dev</A>
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; ------------------------------------------------------------------------
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; _______________________________________________
</I>&gt;<i> &gt; Opensim-dev mailing list
</I>&gt;<i> &gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">Opensim-dev at lists.berlios.de</A>
</I>&gt;<i> &gt; <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">https://lists.berlios.de/mailman/listinfo/opensim-dev</A>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> Opensim-dev mailing list
</I>&gt;<i> <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">Opensim-dev at lists.berlios.de</A>
</I>&gt;<i> <A HREF="https://lists.berlios.de/mailman/listinfo/opensim-dev">https://lists.berlios.de/mailman/listinfo/opensim-dev</A>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="https://lists.berlios.de/pipermail/opensim-dev/attachments/20110328/4baa11a7/attachment.html">https://lists.berlios.de/pipermail/opensim-dev/attachments/20110328/4baa11a7/attachment.html</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="010069.html">[Opensim-dev] networking issues
</A></li>
	<LI>Next message: <A HREF="010072.html">[Opensim-dev] networking issues
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10071">[ date ]</a>
              <a href="thread.html#10071">[ thread ]</a>
              <a href="subject.html#10071">[ subject ]</a>
              <a href="author.html#10071">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/opensim-dev">More information about the Opensim-dev
mailing list</a><br>
</body></html>
